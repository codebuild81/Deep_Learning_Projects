{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1b. Sentiment_Analysis_Embedding_FC_Layer.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"HSImsWg8KrtR","colab_type":"text"},"cell_type":"markdown","source":["Set the seed"]},{"metadata":{"id":"2fynG7CTKrtU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","np.random.seed(42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u1pImHLPKrth","colab_type":"text"},"cell_type":"markdown","source":["Data can be downloaded from Kaggle at the following URL\n","\n","- https://www.kaggle.com/c/word2vec-nlp-tutorial/data"]},{"metadata":{"id":"dn3NW0Y6Krtf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","\n","#Change filepath based on where you have stored the data\n","df = pd.read_csv('kaggle/labeledTrainData.tsv.zip',header=0, delimiter=\"\\t\", quoting=3)\n","\n","print(df.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ycq2gaxWKrt0","colab_type":"text"},"cell_type":"markdown","source":["Split Data into Training and Test Data"]},{"metadata":{"id":"69AK0WaNKrt6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df['review'],\n","    df['sentiment'],\n","    test_size=0.2, \n","    random_state=42\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i_djnYMVKruB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X_train.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vyvYBPHCKruH","colab_type":"text"},"cell_type":"markdown","source":["## Prepare Data"]},{"metadata":{"id":"ctHU3z1GNvHR","colab_type":"text"},"cell_type":"markdown","source":["1.Convert reviews to Number sequences using Tokenizer"]},{"metadata":{"id":"jARgt_VjKruI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing.text import Tokenizer\n","\n","#Vocablury size\n","top_words = 5000\n","t = Tokenizer(num_words=top_words)\n","\n","#Fit tokenizer of training data\n","t.fit_on_texts(X_train.tolist())\n","\n","#Get the word index for each of the word in the review\n","X_train = t.texts_to_sequences(X_train.tolist())\n","X_test = t.texts_to_sequences(X_test.tolist())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Q04H7mZKrum","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Length of different reviews is different\n","print('Length of review# 32 is: ', len(X_train[32]))\n","print('Length of review# 1208 is: ', len(X_train[1208]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SW1w9vpPOuSP","colab_type":"text"},"cell_type":"markdown","source":["2.Pad the sequences - to make every review equal in size"]},{"metadata":{"id":"HM_scpolKru5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing import sequence\n","\n","#Length for each review\n","max_review_length = 300\n","\n","X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,\n","                                 padding='post')\n","\n","X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, \n","                                padding='post')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dv8ShIfuKru8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Length of different reviews should be SAME now\n","print('Length of review# 32 is: ', len(X_train[32]))\n","print('Length of review# 1208 is: ', len(X_train[1208]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O10S28KkrJRd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X_train[1208]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LGWNKBknKrvY","colab_type":"text"},"cell_type":"markdown","source":["## Build the Graph"]},{"metadata":{"id":"6ei6Eg4YKrva","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cc6h4mP5P7FZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define how many numbers per word for Word embeddings\n","embedding_vector_length = 50 \n","\n","#Build a model\n","model = Sequential()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VToUG0wfKrvv","colab_type":"text"},"cell_type":"markdown","source":["Add Embedding layer"]},{"metadata":{"id":"SFJjSzakKrvx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.add(\n","    Embedding(top_words+1, #Vocablury Size, why +1\n","                    embedding_vector_length, #How many numbers per word\n","                    input_length=max_review_length) #Words in each review\n","         )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iSy7vWpBKrv1","colab_type":"text"},"cell_type":"markdown","source":["Output from Embedding is 3 dimension \n","- batch_size x max_review_length x embedding_vector_length. \n","\n","We need to flatten the output for Dense layer"]},{"metadata":{"id":"nKdEVQdxKrv2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Flatten the input\n","model.add(Flatten())\n","\n","#Dense Layers\n","model.add(Dense(200,activation='relu'))\n","model.add(Dense(100,activation='relu'))\n","model.add(Dense(60,activation='relu'))\n","model.add(Dense(30,activation='relu'))\n","\n","#Output layer\n","model.add(Dense(1,activation='sigmoid'))\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"deqoDS9uKrwQ","colab_type":"text"},"cell_type":"markdown","source":["## Execute the graph"]},{"metadata":{"id":"rUG6_UwnKrwQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Change number of epochs appropriately\n","model.fit(X_train,y_train,\n","          epochs=1,\n","          batch_size=128,\n","          shuffle=True, \n","          validation_data=(X_test, y_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MeRoaAu312GK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.predict(X_test[0:2])"],"execution_count":0,"outputs":[]}]}