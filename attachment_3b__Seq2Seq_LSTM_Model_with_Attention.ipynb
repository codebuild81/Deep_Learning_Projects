{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3b. Seq2Seq LSTM Model with Attention.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HL6SiZJT2oUb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Set Seed\n","import numpy as np\n","np.random.seed(42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-lxNfeYx2oUg","colab_type":"text"},"cell_type":"markdown","source":["## 1. Prepare data\n","Data for this exercise can be downloaded from http://www.manythings.org/anki/"]},{"metadata":{"id":"ih9pRZKjBb1e","colab_type":"text"},"cell_type":"markdown","source":["### 1.1 Download and extract sentence pairs"]},{"metadata":{"id":"v53t6LIx4GP6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!wget http://www.manythings.org/anki/hin-eng.zip --quiet"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kBfzcXuX4wUI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import zipfile\n","import io"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rLcBzQc940OL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["zf = zipfile.ZipFile('hin-eng.zip', 'r')\n","\n","#Read all Sentences\n","data = ''\n","with zf.open('hin.txt') as readfile:\n","  for line in io.TextIOWrapper(readfile, 'utf-8'):\n","    data += line\n","\n","#Split sentences\n","data =  data.split('\\n')\n","\n","#lets review the data\n","print('Number of sentences: ', len(data))\n","data[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PF5ZMy-dn1jH","colab_type":"text"},"cell_type":"markdown","source":["### 1.2 Separate out Encoder and Decoder input data"]},{"metadata":{"id":"RN3q2mm42oUp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_text = []\n","decoder_text = []\n","\n","for line in data:\n","    try:\n","        in_txt, out_txt = line.split('\\t')\n","        encoder_text.append(in_txt)\n","        \n","        # Add tab '<start>' as 'start sequence in target\n","        # And '<end>' as End\n","        decoder_text.append('<start> ' + out_txt + ' <end>')\n","    except:\n","        pass #ignore data which goes into error"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V6TdW_s22oUs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_text[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rfWDMX2q2oUu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_text[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T_INkpPE2oU2","colab_type":"text"},"cell_type":"markdown","source":["### 1.3 Build Sequences for Encoder and Decoder Input"]},{"metadata":{"id":"AzgIJwqZ2oU3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing.text import Tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FGUFyI452oU5","colab_type":"text"},"cell_type":"markdown","source":["Encoder tokenizer"]},{"metadata":{"id":"kzg86E_h2oU5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_t = Tokenizer()\n","encoder_t.fit_on_texts(encoder_text)\n","encoder_seq = encoder_t.texts_to_sequences(encoder_text)\n","max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n","encoder_vocab_size = len(encoder_t.word_index)\n","print('Max words in input sentence: ', max_encoder_seq_length)\n","print('Input vocablury: ', encoder_vocab_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n5VEgt2jotqj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_text[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AM4-L-IOSncW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_seq[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SxRm7g5_2oVO","colab_type":"text"},"cell_type":"markdown","source":["Decoder tokenizer"]},{"metadata":{"id":"qX3ALB6d2oVP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_t = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n","decoder_t.fit_on_texts(decoder_text)\n","decoder_seq = decoder_t.texts_to_sequences(decoder_text)\n","max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n","decoder_vocab_size = len(decoder_t.word_index)\n","\n","print('Max words in output sentence: ', max_decoder_seq_length)\n","print('Output vocablury: ', decoder_vocab_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NaywgIDQTOkz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_text[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CRnT4mPaTSOH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_seq[100:105]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OOkCZLP02oVp","colab_type":"text"},"cell_type":"markdown","source":["### 1.4 Padding Sequences"]},{"metadata":{"id":"7sK7hzn62oVq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","\n","encoder_input_data = pad_sequences(encoder_seq, maxlen=max_encoder_seq_length, padding='pre')\n","decoder_input_data = pad_sequences(decoder_seq, maxlen=max_decoder_seq_length, padding='post')\n","\n","print('Encoder input shape: ', encoder_input_data.shape)\n","print('Decoder input shape: ', decoder_input_data.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W0hWqo3K2oV8","colab_type":"text"},"cell_type":"markdown","source":["Integer to Word converter for Decoder data"]},{"metadata":{"id":"YroNA85k2oV9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#This will be used to convert output back to word\n","int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())\n","int_to_word_decoder[15]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cNqNaJ4t2oWB","colab_type":"text"},"cell_type":"markdown","source":["### 1.5 Building Decoder Output data"]},{"metadata":{"id":"E8Jojsni2oWC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n","\n","for i in range(decoder_input_data.shape[0]):\n","    for j in range(1,decoder_input_data.shape[1]):\n","        decoder_target_data[i][j-1] = decoder_input_data[i][j]   \n","\n","decoder_input_data[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WkfOv-Jg2oWP","colab_type":"text"},"cell_type":"markdown","source":["Convert target data in one hot vector"]},{"metadata":{"id":"YLfOe0k52oWQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.utils import  to_categorical\n","\n","#Initialize decoder output matrix to all zeros\n","decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], \n","                                   decoder_input_data.shape[1],\n","                                   len(decoder_t.word_index)+1))\n","\n","#Populate the output matrix by shifting decoder input by 1 step\n","for i in range(decoder_target_data.shape[0]):\n","    for j in range(decoder_target_data.shape[1]):\n","        decoder_target_one_hot[i][j] = to_categorical(decoder_target_data[i][j],\n","                                                      num_classes=len(\n","                                                          decoder_t.word_index)+1) \n","        \n","#Decoder Output size\n","decoder_target_one_hot.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OEaq66iJ2oWX","colab_type":"text"},"cell_type":"markdown","source":["## 2. Building the Training Model"]},{"metadata":{"id":"OevwCnTV2oWY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.layers import Input, LSTM, Dense, Embedding\n","from tensorflow.python.keras.layers import concatenate, dot, Permute, Average\n","from tensorflow.python.keras.layers import Multiply, Activation, Bidirectional\n","from tensorflow.python.keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nEKx9XQI2oWb","colab_type":"text"},"cell_type":"markdown","source":["Define config parameters"]},{"metadata":{"id":"SfHikNyh2oWc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_embedding_size = 50\n","decoder_embedding_size = 50\n","rnn_units = 256"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ktTTJ3t_2oWg","colab_type":"text"},"cell_type":"markdown","source":["### 2.1 Build Encoder layers"]},{"metadata":{"id":"Rx5XaerO2oWm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Encoder Input\n","encoder_inputs = Input(shape=(None,))\n","\n","#Embedding layer \n","encoder_embedding = Embedding(encoder_vocab_size+1, encoder_embedding_size)\n","\n","#Embeding layer output\n","encoder_embedding_output = (encoder_embedding(encoder_inputs))\n","\n","#Define LSTM layer for encoder\n","#Get all hidden states (needed for attention) and last h and c\n","encoder_lstm = Bidirectional(LSTM(rnn_units,return_state=True,\n","                                 return_sequences=True))\n","\n","#Bidirectional encoder will return 5 tensors\n","encoder_all_states, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding_output)\n","#state_h = Average()([forward_h,backward_h])\n","#state_c = Average()([forward_c,backward_c])\n","\n","#Create a list for hidden and cell state\n","encoder_states = [forward_h, forward_c, backward_h, backward_c ]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rxxLV14h2oWy","colab_type":"text"},"cell_type":"markdown","source":["### 2.2 Build Decoder layers"]},{"metadata":{"id":"OSqja3Z72oWy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Decoder input\n","decoder_inputs = Input(shape=(None,))\n","\n","#Embedding Layer\n","decoder_embedding = Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n","decoder_embedding_output = decoder_embedding(decoder_inputs)\n","\n","#Decoder LSTM\n","#Get all hidden states and last h, c\n","decoder_rnn = Bidirectional(LSTM(rnn_units, return_sequences=True, return_state=True))\n","decoder_all_states,_,_,_,_ = decoder_rnn(decoder_embedding_output, initial_state=encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pv6tcL1or2f5","colab_type":"text"},"cell_type":"markdown","source":["Add code for the Attention Layer - start with alignment matrix"]},{"metadata":{"id":"kaNPZDmOr1xM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#1. Dot Product between Decoder_all_states and encoder_all_hidden_states\n","#2. Apply softmax to get Alignment matrix\n","\n","#Dimensions details\n","#decoder_all_states = batch_size x max_decoder_length x rnn_units\n","#encoder_all_states = batch_size x max_encoder_length x rnn_units\n","#score = batch_size x max_decoder_length x max_encoder_length\n","#alignment matrix = batch_size x max_decoder_length x max_encoder_length\n","\n","score = dot([decoder_all_states, encoder_all_states], axes=2)\n","alignment_matrix = Activation('softmax')(score)\n","\n","#Try general and concat approaches to alignment matrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Meh1C1DHr1Oe","colab_type":"text"},"cell_type":"markdown","source":["Build Context Vector"]},{"metadata":{"id":"OyBRKUTsr0e9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Weighted sum of multiplication of Alignment matrix and encoder states\n","# Dimension of context_vector =  batch_size x max_decoder_length x rnn_units\n","context_vector = dot([alignment_matrix, encoder_all_states], axes=[2,1])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ADZ_TKH-25j4","colab_type":"text"},"cell_type":"markdown","source":["Build Attention Vector"]},{"metadata":{"id":"8PPPVFp828r3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Concatenate context vector and decoder_all_states\n","#context_decoder_hidden = batch_size x max_decoder_length x 2*rnn_units\n","#attention_vector = batch_size x max_decoder_length x 128\n","\n","context_decoder_hidden = concatenate([context_vector, decoder_all_states])\n","attention_dense_layer = Dense(128, use_bias=False, \n","                         activation='tanh')\n","attention_vector = attention_dense_layer(context_decoder_hidden)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tyKPLlNt2oW6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Output layer\n","decoder_dense = Dense(decoder_vocab_size + 1, activation='softmax')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6nFd03t02oW8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#With attention input will be attention_vector and not decoder_all_states\n","#decoder_outputs = decoder_dense(decoder_all_states)\n","decoder_outputs = decoder_dense(attention_vector)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4irUZFFJ2oW-","colab_type":"text"},"cell_type":"markdown","source":["### 2.3 Build Model using both Encoder and Decoder layers"]},{"metadata":{"id":"35Wan_LF2oW-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.models import Model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8onZYQE-2oXC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"owbIRm0r2oXJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.compile(optimizer='adam', loss='categorical_crossentropy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wDgLXB3wiT7l","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mlutxik62oXL","colab_type":"text"},"cell_type":"markdown","source":["## 3. Train the model"]},{"metadata":{"id":"rqqgnzvC2oXM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n","          batch_size=32,\n","          epochs=100,\n","          validation_split=0.2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q0E7j5Cf2gaS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.save('seq2seq_enghin_trg_bi_attention.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"diNsT2872oXO","colab_type":"text"},"cell_type":"markdown","source":["## 4. Building Model for Prediction"]},{"metadata":{"id":"i1s0wEEW2oXP","colab_type":"text"},"cell_type":"markdown","source":["### 4.1 Build the Encoder Model to predict Encoder States"]},{"metadata":{"id":"zG_a4adu2oXQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Get both last c and h as well as encoder_all_states for Attention\n","encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_all_states] + \n","                      encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H-9JR6I72oXR","colab_type":"text"},"cell_type":"markdown","source":["### 4.2 Build the Decoder Model \n","\n","1. Define Input for both 'h' state and 'c' state initialization\n","2. Get RNN outputs along with h and c state\n","3. Define Decoder Output\n","4. Build Model"]},{"metadata":{"id":"OwW75R1m2oXR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#State h and c from Encoder\n","initial_fwd_h = Input(shape=(rnn_units,))\n","initial_fwd_c = Input(shape=(rnn_units,))\n","initial_bkwd_h = Input(shape=(rnn_units,))\n","initial_bkwd_c = Input(shape=(rnn_units,))\n","#Build list of state inputs \n","decoder_states_inputs = [initial_fwd_h, initial_fwd_c,\n","                        initial_bkwd_h, initial_bkwd_c]\n","\n","#Input for Attention layer\n","encoder_outputs = Input(shape=(max_encoder_seq_length, 2*rnn_units,))\n","\n","#Get RNN outputs and state(s) using trained layers\n","x = decoder_embedding(decoder_inputs)\n","rnn_outputs, f_state_h, f_state_c, b_state_h, b_state_c = decoder_rnn(x,\n","                                                                      initial_state=decoder_states_inputs)\n","\n","#Why do we need this?\n","decoder_states = [f_state_h, f_state_c, b_state_h, b_state_c]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0K9vuH3gIUlL","colab_type":"text"},"cell_type":"markdown","source":["Build Attention Layer"]},{"metadata":{"id":"l8UIHU5GIUCA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Alignment score\n","p_score = dot([rnn_outputs, encoder_outputs], axes=2)\n","\n","#Perform softmax to get Alignment matrix\n","p_alignment_matrix = Activation('softmax')(p_score)\n","\n","#Context Vector\n","p_context_vector = dot([p_alignment_matrix, encoder_outputs], axes=[2,1])\n","\n","#Build Attention Vector\n","# 1. Caoncatenate both context vector and decoder outputs\n","# 2. Feed it to the Dense layer \n","p_context_decoder_hidden = concatenate([p_context_vector, rnn_outputs])\n","p_attention_vector = attention_dense_layer(p_context_decoder_hidden)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlSOV9tU2oXd","colab_type":"text"},"cell_type":"markdown","source":["get Decoder output"]},{"metadata":{"id":"piCi4D3I2oXe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#decoder_outputs = decoder_dense(rnn_outputs)\n","decoder_outputs = decoder_dense(p_attention_vector)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UvP7HOzL2oXf","colab_type":"text"},"cell_type":"markdown","source":["Build Decoder Model"]},{"metadata":{"id":"_Kbc3jAe2oXg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder_model = Model([decoder_inputs] #<Start> sequence and then next words\n","                      + decoder_states_inputs #Encoder States \n","                      + [encoder_outputs],  #For Attention layer\n","                     [decoder_outputs] + decoder_states + [p_alignment_matrix])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wJyeIiyN2oXj","colab_type":"text"},"cell_type":"markdown","source":["## 5.0 Predicting Output"]},{"metadata":{"id":"CQKbrF9b2oXj","colab_type":"text"},"cell_type":"markdown","source":["Build a prediction function"]},{"metadata":{"id":"ulVF4IHE2oXk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def decode_sentence(input_sequence):\n","    \n","    #Get the encoder state values\n","    encoder_output =  encoder_model.predict(input_sequence)\n","    decoder_initial_states_value = encoder_output[1:]    \n","    encoded_seqs = encoder_output[0]\n","       \n","    \n","    #decoder_initial_states_value = [encoder_last_h, encoder_last_c]\n","    \n","    #Build a sequence with '<start>' - starting sequence for Decoder\n","    target_seq = np.zeros((1,1))    \n","    target_seq[0][0] = decoder_t.word_index['<start>']\n","    \n","    #flag to check if prediction should be stopped\n","    stop_loop = False\n","    \n","    #Initialize predicted sentence\n","    predicted_sentence = ''\n","    \n","    #start the loop\n","    while not stop_loop:\n","        \n","        predicted_outputs, f_h, f_c, b_h, b_c, a = decoder_model.predict([target_seq] +\n","                                                           decoder_initial_states_value +\n","                                                           [encoded_seqs])\n","        \n","        #Get the predicted output with highest probability\n","        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n","        \n","        #Get the predicted word from predicter integer\n","        if (predicted_output == 0):\n","            predicted_word = ' '\n","        else:\n","            predicted_word = int_to_word_decoder[predicted_output]\n","        \n","        #Check if prediction should stop\n","        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n","            \n","            stop_loop = True\n","            continue\n","                    \n","        #Updated predicted sentence\n","        if (len(predicted_sentence) == 0):\n","            predicted_sentence = predicted_word\n","        else:\n","            predicted_sentence = predicted_sentence + ' ' + predicted_word\n","            \n","        #Update target_seq to be the predicted word index\n","        target_seq[0][0] = predicted_output\n","        \n","        #Update initial states value for decoder\n","        decoder_initial_states_value = [f_h,f_c,b_h,b_c]\n","        \n","        #Uncomment this line to print Alignment Matrix\n","        #print (a)\n","        \n","    \n","    return predicted_sentence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eIcTe2V32oXl","colab_type":"text"},"cell_type":"markdown","source":["Call Prediction function above"]},{"metadata":{"id":"vYC_2syR2oXm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Get a random sentence\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","print(start_num)\n","\n","for i in range(start_num, start_num + 10):\n","    input_seq = encoder_input_data[i : i+1]    \n","    predicted_sentence = decode_sentence(input_seq)\n","    print('--------')\n","    print ('Input sentence: ', encoder_text[i])\n","    print ('Predicted sentence: ', predicted_sentence )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KgZeXBIwy-NB","colab_type":"text"},"cell_type":"markdown","source":["## 6. Save Prediction models and tokenizers "]},{"metadata":{"id":"4cPhW3Sfy8h6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Save encoder and decoder model for Prediction\n","encoder_model.compile(optimizer='adam', loss='mse')\n","decoder_model.compile(optimizer='adam', loss='categorical_crossentropy')\n","encoder_model.save('drive/AI-ML/models/seq2seq_encoder_eng_hin.hd5')\n","decoder_model.save('drive/AI-ML/models/seq2seq_decoder_eng_hin.hd5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"05_mrMj2zTH9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Save tokenizers\n","import pickle\n","\n","pickle.dump(encoder_t,open('drive/AI-ML/models/encoder_tokenizer_eng','wb'))\n","pickle.dump(decoder_t,open('drive/AI-ML/models/decoder_tokenizer_hin','wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jikCiiKLSc0A","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_input_data[429]"],"execution_count":0,"outputs":[]}]}