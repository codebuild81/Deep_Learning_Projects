{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. MNIST_Classification_DNN.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"udXq5MTKxOjf","colab_type":"text"},"cell_type":"markdown","source":["# MNIST Classification with DNN"]},{"metadata":{"id":"h3VejzglxOjg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MqVPKByixOjk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"18KTJLLlzXFI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Set random seed for reproducible results\n","tf.set_random_seed(42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LajgRMShxOjm","colab_type":"text"},"cell_type":"markdown","source":["## Step 1 : Collect Data"]},{"metadata":{"id":"Sk_xowpZxOjo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EpAuPcuDxOjw","colab_type":"text"},"cell_type":"markdown","source":["Get Training and Test Data"]},{"metadata":{"id":"kDK7B01nxOjx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["trainX = mnist.train.images\n","trainY = mnist.train.labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mOkcRmnCxOjz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["testX = mnist.test.images\n","testY = mnist.test.labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mj-c_ZowxOj7","colab_type":"text"},"cell_type":"markdown","source":["Lets define some parameters"]},{"metadata":{"id":"TYq9xYm1xOj8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Directory to save logs and graph, change it as needed\n","logs_path=''\n","\n","#Learning rate\n","learning_rate = 0.03\n","\n","#Number of input features - MNIST has 784 features\n","n_features = trainX.shape[1]\n","\n","#Number of possible output classess - 10 for MNIST\n","n_classes = trainY.shape[1]\n","\n","#Model name for storage\n","model_name = 'mnist_dnn.ckpt'\n","\n","#How many examples to feed for training at one time\n","batch_size = 100\n","\n","#How many times all the data to be shown\n","training_epochs = 60\n","\n","#Define number of neurons in 4 hidden layers\n","K = 200\n","L = 100\n","M = 60\n","N = 30"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kjqpMgJHxOj_","colab_type":"text"},"cell_type":"markdown","source":["# Build the Graph"]},{"metadata":{"id":"mWBUbx3-xOkA","colab_type":"text"},"cell_type":"markdown","source":["Input placeholders"]},{"metadata":{"id":"-oEuMNRpxOkE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('input'):\n","    \n","    # None -> batch size can be any size, with n_features\n","    x = tf.placeholder(tf.float32, shape=[None, n_features], name=\"x-input\") \n","    \n","    # target n_classes output classes\n","    y_ = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y-input\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iitA4a3xxOkJ","colab_type":"text"},"cell_type":"markdown","source":["Layer 1"]},{"metadata":{"id":"RTDC2G1gxOkK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('layer_1'):\n","    W1 = tf.Variable(tf.truncated_normal([n_features, K], stddev=0.1))\n","    b1 = tf.Variable(tf.zeros([K]))\n","    Y1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),b1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nAaxSfOixOkP","colab_type":"text"},"cell_type":"markdown","source":["Layer 2"]},{"metadata":{"id":"4B8S5_tdxOkQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('layer_2'):\n","    W2 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1))\n","    b2 = tf.Variable(tf.zeros([L]))\n","    Y2 = tf.nn.sigmoid(tf.add(tf.matmul(Y1,W2),b2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gwMrB6yOxOkS","colab_type":"text"},"cell_type":"markdown","source":["Layer 3"]},{"metadata":{"id":"WiQy4pEaxOkT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('layer_3'):\n","    W3 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n","    b3 = tf.Variable(tf.zeros([M]))\n","    Y3 = tf.nn.sigmoid(tf.add(tf.matmul(Y2,W3),b3))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EUqvBlhYxOkX","colab_type":"text"},"cell_type":"markdown","source":["Layer 4"]},{"metadata":{"id":"JLdRZEbKxOkZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('layer_4'):\n","    W4 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n","    b4 = tf.Variable(tf.zeros([N]))\n","    Y4 = tf.nn.sigmoid(tf.add(tf.matmul(Y3,W4),b4))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1xkuvikqxOkd","colab_type":"text"},"cell_type":"markdown","source":["Output Layer   "]},{"metadata":{"id":"3JT7E6afxOkd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope(\"Output\"):\n","    W5 = tf.Variable(tf.truncated_normal([N,n_classes], stddev=0.1))\n","    b5 = tf.Variable(tf.zeros([n_classes]))\n","    \n","    #To use more stable version of cross_entropy loss in tensorflow\n","    Ylogits = tf.matmul(Y4,W5) + b5\n","    \n","    #Actual prediction\n","    y = tf.nn.softmax(tf.matmul(Y4,W5) + b5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KZOn_BoZxOkf","colab_type":"text"},"cell_type":"markdown","source":["Loss"]},{"metadata":{"id":"7NtXNHN_xOkg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('Loss'):\n","    \n","    #More stable version of cross_entroy    \n","    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=y_)\n","    cross_entropy = tf.reduce_mean(cross_entropy)*100\n","    \n","    #Earlier cross_entropy implementation\n","    #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3JiyaGMExOki","colab_type":"text"},"cell_type":"markdown","source":["GradientDescent Optimizer"]},{"metadata":{"id":"ROup4Vn0xOkj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('train'):        \n","    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"LjmzY12HxOkl","colab_type":"text"},"cell_type":"markdown","source":["Model Accuracy"]},{"metadata":{"id":"xCeOvdLxxOkm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.name_scope('Accuracy'):\n","    \n","    #Get the number with highest probability\n","    prediction = tf.argmax(y,1,name=\"Predict\")\n","    \n","    #Compare prediction with actual\n","    correct_prediction = tf.equal(prediction, tf.argmax(y_,1))\n","    \n","    #Calculate mean accuracy across all data examples\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),\n","                              name=\"accuracy\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fCEYojdmxOkp","colab_type":"text"},"cell_type":"markdown","source":["Loss and Accuracy Logging"]},{"metadata":{"id":"BmJwQLyKxOkq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Training loss and accuracy\n","training_loss = tf.summary.scalar(\"training_loss\", cross_entropy)\n","training_accuracy = tf.summary.scalar(\"training_accuracy\", accuracy)\n","\n","#Test loss and accuracy\n","test_loss = tf.summary.scalar(\"test_loss\", cross_entropy)\n","test_accuracy = tf.summary.scalar(\"test_accuracy\", accuracy)\n","\n","# create log writer object\n","writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_q0h_kp9xOkv","colab_type":"text"},"cell_type":"markdown","source":["# Execute the Graph"]},{"metadata":{"id":"0-QWn2kDxOkv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Start Graph execution\n","with tf.Session() as sess:\n","    \n","    # variables need to be initialized before we can use them\n","    sess.run(tf.global_variables_initializer())\n","   \n","    # perform training cycles\n","    for epoch in range(training_epochs):\n","        \n","        # number of batches in one epoch\n","        batch_count = int(trainX.shape[0]/batch_size)\n","        \n","        for i in range(batch_count):\n","            batch_x  = trainX[i*batch_size:i*batch_size+batch_size]\n","            batch_y  = trainY[i*batch_size:i*batch_size+batch_size]\n","\n","            # perform the operations we defined earlier on batch\n","            _,acc,loss = sess.run([train_op, training_accuracy,training_loss], \n","                                  feed_dict={x: batch_x, y_: batch_y})\n","            \n","            #log training accuracy and loss\n","            writer.add_summary(acc, epoch * batch_count + i)\n","            writer.add_summary(loss, epoch * batch_count + i)    \n","                       \n","        #Test loss and accuracy\n","        #Please note we are giving test data\n","        acc,loss = sess.run([test_accuracy,test_loss],\n","                                   feed_dict={x: testX, y_: testY})\n","        \n","        writer.add_summary(acc, epoch * batch_count + i)\n","        writer.add_summary(loss, epoch * batch_count + i)\n","        \n","        if epoch % 5 == 0: \n","            print (\"Epoch: \", epoch)\n","            print (\"Test Accuracy: \", accuracy.eval(feed_dict={x: testX, \n","                                                               y_: testY}))               \n","    \n","    \n","    #Create a Saver to save the graph\n","    saver = tf.train.Saver()\n","    saver.save(sess, logs_path + '/' + model_name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W4DxqK0ArRxv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}