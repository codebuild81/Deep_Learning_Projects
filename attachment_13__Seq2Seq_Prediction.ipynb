{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model('models/seq2seq_encoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "decoder_model = load_model('models/seq2seq_decoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder_t = pickle.load(open('models/encoder_tokenizer_eng','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "decoder_t = pickle.load(open('models/decoder_tokenizer_hin','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 22 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length = 27 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Function to generate Padded sequences for Input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def encode_input(input_str):\n",
    "    \n",
    "    #Convert words to indexes\n",
    "    encoder_seq = encoder_t.texts_to_sequences([input_str])\n",
    "    \n",
    "    #Pad sequences\n",
    "    encoder_input_data = pad_sequences(encoder_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "    \n",
    "    return encoder_input_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_str):\n",
    "    \n",
    "    #Convert input string to padded sequence\n",
    "    input_seq = encode_input(input_str)\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted output with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter integer\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value forr decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if __name__== '__main__':\n",
    "    print(decode_sentence('How are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं भूख से मरा जा रहा हूँ।'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(\"I'm starving.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
